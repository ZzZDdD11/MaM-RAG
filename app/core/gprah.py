# app/core/graph.py
import operator
import logging
from typing import Annotated, List, TypedDict, Dict, Any
from app.modules.retrieval.graph_retrieval import MineralGraphRetriever
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from app.modules.retrieval.vector_retrieval import MineralVectorRetriever
# å¯¼å…¥é…ç½®å•ä¾‹
from app.core.config import settings
from app.modules.retrieval.web_retrieval import MineralWebRetriever
# å¯¼å…¥ç°æœ‰çš„ä¸šåŠ¡ç»„ä»¶
from app.modules.generation.answer_generator import generator
from app.core.router import router
# from legacy.vector_retrieval import VectorRetrieval
# from legacy.graph_retrieval import GraphRetrieval

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# --- 1. å®šä¹‰çŠ¶æ€ (State) ---
# è¿™é‡Œçš„å­—æ®µå¿…é¡»è¦†ç›– app/api/routers/chat.py ä¸­ initial_state çš„æ‰€æœ‰ key
class AgentState(TypedDict):
    original_query: str
    sub_queries: List[str]
    # ä½¿ç”¨ operator.add å®ç°åˆ—è¡¨è‡ªåŠ¨åˆå¹¶ (å¹¶è¡Œæ£€ç´¢æ—¶ä¸ä¼šäº’ç›¸è¦†ç›–)
    retrieved_contents: Annotated[List[str], operator.add]
    final_answer: str
    routes: List[str]

# --- 2. åˆå§‹åŒ–å·¥å…·å®ä¾‹ ---
# æˆ‘ä»¬åˆ©ç”¨å…¨å±€ settings åˆå§‹åŒ–å•ä¾‹ï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°åŠ è½½æ¨¡å‹
try:
    logger.info("æ­£åœ¨åˆå§‹åŒ– Graph ç»„ä»¶...")
    _decompose_agent = DecomposeAgent(settings)
    _summary_agent = SummaryAgent(settings)
    
    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆå§‹åŒ–æ£€ç´¢å™¨ (è™½ç„¶è¿™é‡Œåˆå§‹åŒ–äº†ï¼Œä½†åœ¨ Node ä¸­æˆ‘ä»¬ä¼šå†æ¬¡æ£€æŸ¥è¯·æ±‚çº§å¼€å…³)
    # _vector_retriever = VectorRetrieval(settings)
    # _graph_retriever = GraphRetrieval(settings)
    logger.info("Graph ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    logger.error(f"Graph ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    # è¿™é‡Œä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡å¯åŠ¨ï¼Œä½†åœ¨è°ƒç”¨æ—¶å¯èƒ½ä¼šæŠ¥é”™
    _decompose_agent = None
    _summary_agent = None
    _vector_retriever = None
    _graph_retriever = None

# --- 3. å®šä¹‰èŠ‚ç‚¹ (Nodes) ---

def node_decompose(state: AgentState, config: RunnableConfig):
    """
    èŠ‚ç‚¹ï¼šé—®é¢˜åˆ†è§£
    """
    query = state["original_query"]
    # ä» metadata è·å–å¯èƒ½çš„ trace_id ç”¨äºæ—¥å¿—
    tid = config.get("configurable", {}).get("thread_id", "N/A")
    logger.info(f"[{tid}] [Node: Decompose] å¤„ç†: {query}")
    
    if not _decompose_agent:
        return {"sub_queries": [query]}

    try:
        # è°ƒç”¨åŸæœ‰é€»è¾‘
        sub_queries = _decompose_agent.decompose(query)
        # å½’ä¸€åŒ–ä¸ºåˆ—è¡¨
        if isinstance(sub_queries, str):
            sub_queries = [sub_queries]
        return {"sub_queries": sub_queries}
    except Exception as e:
        logger.error(f"åˆ†è§£å¤±è´¥: {e}")
        return {"sub_queries": [query]}

def node_vector_search(state: AgentState, config: RunnableConfig):
    """
    èŠ‚ç‚¹ï¼šå‘é‡æ£€ç´¢
    """
    # 1. è·å–è¿è¡Œæ—¶é…ç½® (æ¥è‡ª API è¯·æ±‚)
    meta = config.get("metadata", {})
    # é»˜è®¤ä¸º Trueï¼Œé™¤éæ˜¾å¼è®¾ä¸º False
    if meta.get("enable_vector", True) is False: 
        return {"retrieved_contents": []}
    # è·å–åŠ¨æ€å‚æ•°
    top_k = meta.get("top_k", 3)
    # [ä¿®æ”¹ç‚¹ 2]: å®ä¾‹åŒ–ä½ çš„æ–°æ£€ç´¢å™¨
    # æ€è€ƒï¼šè¿™é‡Œéœ€è¦ä¼ å“ªäº›å‚æ•°ï¼Ÿæç¤ºï¼šçœ‹ä½ åœ¨ MineralVectorRetriever é‡Œå®šä¹‰çš„ Field
    retriever = MineralVectorRetriever(
        top_k=top_k,
        use_rerank=True,      # é»˜è®¤å¼€å¯é‡æ’åº
        search_k=top_k * 10   # è‡ªåŠ¨è®¾å®šç²—æ’æ•°é‡
    )

    queries = state["sub_queries"]
    top_k = meta.get("top_k", 3)
    
    results = []

    for q in queries:
        docs = retriever.invoke(q)
        for i, doc in enumerate(docs):
            score = doc.metadata.get("rerank_score", 0)
            # æ„é€ å­—ç¬¦ä¸²
            formatted = f"[Vector Source] (Score:{score:.2f})\n Content:{doc.page_content}"
            results.append(formatted)
    return {"retrieved_contents": results}


def node_graph_search(state: AgentState, config: RunnableConfig):
    """
    èŠ‚ç‚¹ï¼šå›¾è°±æ£€ç´¢ (å‡çº§ç‰ˆ)
    """
    meta = config.get("metadata", {})
    if meta.get("enable_graph", True) is False:
        return {"retrieved_contents": []}

    # å®ä¾‹åŒ–æ£€ç´¢å™¨
    retriever = MineralGraphRetriever(level=1)
    
    queries = state["sub_queries"]
    results = []
    
    for q in queries:
        try:
            # è°ƒç”¨ invoke
            docs = retriever.invoke(q)
            
            for doc in docs:
                # åŠ ä¸Š [Graph Source] æ ‡è®°
                formatted = f"[Graph Source] (Entities: {doc.metadata.get('entities')})\nContent: {doc.page_content}"
                results.append(formatted)
                
        except Exception as e:
            logger.error(f"å›¾è°±æ£€ç´¢å‡ºé”™: {e}")
            
    return {"retrieved_contents": results}

def node_web_search(state: AgentState, config: RunnableConfig):
    """
    èŠ‚ç‚¹ï¼šè”ç½‘æ£€ç´¢
    """
    meta = config.get("metadata", {})
    # æ£€æŸ¥å¼€å…³ï¼Œé»˜è®¤å…³é—­ (False)ï¼Œå› ä¸ºè”ç½‘æ¯”è¾ƒæ…¢
    if meta.get("enable_web", False) is False:
        return {"retrieved_contents": []}

    # å®ä¾‹åŒ–æ£€ç´¢å™¨
    retriever = MineralWebRetriever(top_k=3)
    
    queries = state["sub_queries"]
    results = []
    
    # é€šå¸¸è”ç½‘æœç´¢åªéœ€è¦æœåŸå§‹é—®é¢˜ï¼Œæˆ–è€…ç¬¬ä¸€ä¸ªå­é—®é¢˜
    # æœå¤ªå¤šä¼šè¢«å° IPï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬åªæœç¬¬ä¸€ä¸ª query
    target_query = queries[0] if queries else state["original_query"]
    
    try:
        # è°ƒç”¨ invoke
        docs = retriever.invoke(target_query)
        
        for doc in docs:
            # æ ¼å¼åŒ–è¾“å‡º
            formatted = f"[Web Source] ({doc.metadata.get('source')})\nContent: {doc.page_content}"
            results.append(formatted)
            
    except Exception as e:
        print(f"è”ç½‘æ£€ç´¢å¤±è´¥: {e}")
            
    return {"retrieved_contents": results}

# app/core/graph.py

def node_generate(state: AgentState):
    """
    èŠ‚ç‚¹ï¼šç”Ÿæˆå›ç­” (Final Synthesis)
    """
    query = state["original_query"]
    contexts = state["retrieved_contents"]
    routes = state.get("routes", []) # è·å–è·¯ç”±ç»“æœ
    
    # ğŸ” æ ¸å¿ƒä¿®æ”¹ï¼šåˆ¤æ–­é€»è¾‘
    
    # æƒ…å†µ 1: å¦‚æœè·¯ç”±å™¨æ˜ç¡®è¯´æ˜¯ 'generate' (é—²èŠ)ï¼Œç›´æ¥èµ°é—²èŠæ¨¡å¼
    if "generate" in routes:
        answer = generator.chitchat(query)
        return {"final_answer": answer}

    # æƒ…å†µ 2: å¦‚æœè·¯ç”±å™¨æƒ³æŸ¥ï¼Œä½†æ²¡æŸ¥åˆ°ä¸œè¥¿ (Context ä¸ºç©º)
    if not contexts:
        return {"final_answer": "æŠ±æ­‰ï¼Œç»è¿‡å¤šæºæ£€ç´¢ï¼ˆå‘é‡ã€å›¾è°±ã€ç½‘ç»œï¼‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"}

    # æƒ…å†µ 3: æœ‰ä¸Šä¸‹æ–‡ï¼Œèµ° RAG æ¨¡å¼
    try:
        answer = generator.generate(query, contexts)
        return {"final_answer": answer}
        
    except Exception as e:
        return {"final_answer": f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"}
    
def node_router(state: AgentState):
    """
    ç¬¬ä¸€ç«™ï¼šåˆ†æç”¨æˆ·æ„å›¾
    """
    question = state["original_query"]
    # è°ƒç”¨è·¯ç”±å™¨
    decision = router.route(question)
    
    # è¿™é‡Œçš„ sub_queries æš‚æ—¶ç›´æ¥ç”¨åŸé—®é¢˜
    # (å¦‚æœä¿ç•™ä¹‹å‰çš„ Decompose é€»è¾‘ï¼Œå¯ä»¥æŠŠ Decompose æ”¾åœ¨ Router ä¹‹å)
    return {
        "routes": decision, 
        "sub_queries": [question] 
    }

def route_decision(state: AgentState):
    """
    äº¤é€šæŒ‡æŒ¥å®˜ï¼šæ ¹æ® State ä¸­çš„ routes å†³å®šä¸‹ä¸€æ­¥å»å“ªé‡Œ
    è¿”å›çš„æ˜¯ä¸€ä¸ª listï¼ŒLangGraph ä¼šå¹¶å‘æ‰§è¡Œè¿™äº›èŠ‚ç‚¹
    """
    routes = state["routes"]
    next_nodes = []
    
    if "vector" in routes:
        next_nodes.append("vector_search")
    if "graph" in routes:
        next_nodes.append("graph_search")
    if "web" in routes:
        next_nodes.append("web_search")
        
    # å¦‚æœåˆ—è¡¨ä¸ºç©º (æ¯”å¦‚ routes=['generate'])ï¼Œæˆ–è€…æ²¡é€‰ä¸­ä»»ä½•æ£€ç´¢æº
    if not next_nodes:
        return ["generate"] # ç›´æ¥å»ç”Ÿæˆ
        
    return next_nodes

# --- 4. æ„å»ºå·¥ä½œæµ (Graph Construction) ---

workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("router_node", node_router)
workflow.add_node("decompose", node_decompose)
workflow.add_node("vector_search", node_vector_search)
workflow.add_node("graph_search", node_graph_search)
workflow.add_node("web_search", node_web_search) # éœ€è¦æ—¶å–æ¶ˆæ³¨é‡Š
workflow.add_node("generate", node_generate)

# å®šä¹‰æµç¨‹
# 1. 
workflow.set_entry_point("router_node")
# 2. 
workflow.add_conditional_edges(
    "router_node",
    route_decision,
    # æ˜ å°„å­—å…¸ (å¯é€‰ï¼Œä½†å†™ä¸Šæ›´è§„èŒƒ)
    {
        "vector_search": "vector_search",
        "graph_search": "graph_search",
        "web_search": "web_search",
        "generate": "generate"
    }
)

# 4. æ±‡èš (æ£€ç´¢èŠ‚ç‚¹ -> ç”ŸæˆèŠ‚ç‚¹)
workflow.add_edge("vector_search", "generate")
workflow.add_edge("graph_search", "generate")
workflow.add_edge("web_search", "generate")

# 5. ç»ˆç‚¹
workflow.add_edge("generate", END)


# ç¼–è¯‘åº”ç”¨
app_graph = workflow.compile()