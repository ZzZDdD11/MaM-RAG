# app/core/graph_extract.py
import logging
from typing import List
from langchain_core.documents import Document
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
# å¯¼å…¥å›¾æ•°æ®åº“è¿æ¥
from app.core.graph_store import get_graph_store
from app.core.config import settings
import os
from dotenv import load_dotenv
load_dotenv()

logger = logging.getLogger(__name__)

class GraphExtractor:
    _llm = None
    _transformer = None

    @classmethod
    def _init_llm(cls):
        # ä¸“é—¨ç”¨äºæŠ½å–çš„ LLM
        # å»ºè®®è®¾ç½® temperature=0ï¼Œè®©æå–ç»“æœæ›´ç¨³å®š
        cls._llm = ChatOllama(
            base_url="http://localhost:11434",
            # å»ºè®®ç”¨ qwen2.5:7b æˆ– qwen2.5:1.5b
            # 7b æŠ½å–æ•ˆæœæ›´å¥½ï¼Œ1.5b é€Ÿåº¦æ›´å¿«
            model="qwen2.5:7b", 
            temperature=0,
        )
        
        # åˆå§‹åŒ–è½¬æ¢å™¨
        # ä½ å¯ä»¥åœ¨è¿™é‡Œé™åˆ¶å…è®¸çš„èŠ‚ç‚¹ç±»å‹å’Œå…³ç³»ç±»å‹ï¼Œæˆ–è€…è®©å®ƒè‡ªç”±å‘æŒ¥
        cls._transformer = LLMGraphTransformer(
            llm=cls._llm,
            # allowed_nodes=["Mineral", "Rock", "Location", "Property"], # å¯é€‰ï¼šé™åˆ¶èŠ‚ç‚¹ç±»å‹
            # allowed_relationships=["ASSOCIATED_WITH", "LOCATED_IN", "HAS_PROPERTY"], # å¯é€‰ï¼šé™åˆ¶å…³ç³»
        )

    @classmethod
    def process_and_store(cls, chunks: List[Document]):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šæå– -> å­˜å‚¨
        """
        if cls._transformer is None:
            cls._init_llm()
            
        logger.info(f"â›ï¸ [Graph] å¼€å§‹ä» {len(chunks)} ä¸ªæ–‡æœ¬å—ä¸­æŠ½å–çŸ¥è¯† (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
        
        try:
            # 1. LLM æŠ½å– (è¿™ä¸€æ­¥æœ€æ…¢)
            # convert_to_graph_documents ä¼šæŠŠ Document åˆ—è¡¨è½¬æ¢æˆ GraphDocument åˆ—è¡¨
            graph_documents = cls._transformer.convert_to_graph_documents(chunks) # type: ignore
            
            logger.info(f"ğŸ§© [Graph] æŠ½å–å®Œæˆï¼Œå‡†å¤‡å†™å…¥ Neo4j...")
            
            # 2. å†™å…¥ Neo4j
            graph_store = get_graph_store()
            # include_source=True ä¼šæŠŠåŸå§‹æ–‡æœ¬ä½œä¸ºå±æ€§å­˜åˆ°èŠ‚ç‚¹é‡Œï¼Œæ–¹ä¾¿æº¯æº
            graph_store.add_graph_documents(
                graph_documents, 
                include_source=True
            )
            
            logger.info(f"âœ… [Graph] çŸ¥è¯†å›¾è°±å…¥åº“æˆåŠŸï¼ç”Ÿæˆçš„èŠ‚ç‚¹å’Œå…³ç³»å·²ä¿å­˜ã€‚")
            
        except Exception as e:
            logger.error(f"âŒ [Graph] æŠ½å–æˆ–å­˜å‚¨å¤±è´¥: {e}", exc_info=True)
            # æ³¨æ„ï¼šå›¾è°±å¤±è´¥ä¸åº”å½±å“å‘é‡åº“çš„æˆåŠŸï¼Œæ‰€ä»¥è¿™é‡Œåªè®°å½•æ—¥å¿—ï¼Œä¸æŠ›å‡ºå¼‚å¸¸ä¸­æ–­æµç¨‹

# æ–¹ä¾¿è°ƒç”¨çš„å‡½æ•°
def extract_and_store_graph(chunks: List[Document]):
    return GraphExtractor.process_and_store(chunks)